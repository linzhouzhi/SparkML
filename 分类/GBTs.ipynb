{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient-Boosted Trees (GBTs)\n",
    "GBTs 是多棵决策树的组合。GDTs 通过多次迭代训练决策树来最小化损失函数。和决策树一样、GVTs 处理类别特征，不需要特征扩展就能处理多分类，而且可以知道非线性特征的相互作用。  \n",
    "MLlib GBTs 通过使用，连续特征和分类特征来支持二分类和回归，MLlib 实现 GBTs使用现有的决策树接口。详情可以参阅决策树相关内容。  \n",
    "注：GBTs 尚不支持多分类。对于多分类问题，请使用决策树、或随机森林。  \n",
    "## Basic algorithm\n",
    "梯度增强迭代训练一个序列的决策树。在每次迭代中，该算法使用当前预测值的集合和真实值比较。重新标记数据集，把更多的重点放在训练那些预测效果比较差的数据集上。因此，在下一次迭代中，决策树将有助于纠正以前的错误。  \n",
    "重新标记实例的具体方法是通过损失函数（下面讨论）。在每一次迭代 GBTs 降低训练数据的误差通过损失函数。\n",
    "## Losses\n",
    "下面的表格列出来目前 MLlib 支持的 GBTS 损失函数。注意，每一个损失函数只适用于分类或回归而不是两个都适用。\n",
    "符号说明: N = number of instances. ${y_i}$ = label of instance i. $x_i$ = features of instance i. $F(x_i)$ = model’s predicted label for instance i.\n",
    "\n",
    "|    Loss   |   Task   |  Formula  | Description |\n",
    "| ---- | ---- | ---- |\n",
    "| Log Loss | Classification | $2 \\sum_{i=1}^{N} \\log(1+\\exp(-2 y_i F(x_i)))$ | Twice binomial negative log likelihood. |\n",
    "| Squared Error | Regression | $\\sum_{i=1}^{N} (y_i - F(x_i))^2$ |Also called L2 loss. Default loss for regression tasks. |\n",
    "| Absolute Error | Regression | $\\sum_{i=1}^{N} |y_i - F(x_i)|$ |Also called L1 loss. Can be more robust to outliers than Squared Error. |\n",
    "\n",
    "## Usage tips\n",
    "下面我们将详细说明 GBTs 中各种参数的使用，其中忽略了一些决策树参数，因为这些都包括在决策树章节里面。  \n",
    "* loss:See the section above for information on losses and their applicability to tasks (classification vs. regression). Different losses can give significantly different results, depending on the dataset.  \n",
    "* numIterations: This sets the number of trees in the ensemble. Each iteration produces one tree. Increasing this number makes the model more expressive, improving training data accuracy. However, test-time accuracy may suffer if this is too large. \n",
    "* learningRate: This parameter should not need to be tuned. If the algorithm behavior seems unstable, decreasing this value may improve stability.\n",
    "* algo: The algorithm or task (classification vs. regression) is set using the tree [Strategy] parameter.\n",
    "\n",
    "## Validation while training\n",
    "Gradient boosting can overfit when trained with more trees. In order to prevent overfitting, it is useful to validate while training. The method runWithValidation has been provided to make use of this option. It takes a pair of RDD’s as arguments, the first one being the training dataset and the second being the validation dataset.  \n",
    "Gradient boosting can overfit when trained with more trees. In order to prevent overfitting, it is useful to validate while training. The method runWithValidation has been provided to make use of this option. It takes a pair of RDD’s as arguments, the first one being the training dataset and the second being the validation dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "The example below demonstrates how to load a LIBSVM data file, parse it as an RDD of LabeledPoint and then perform classification using Gradient-Boosted Trees with log loss. The test error is calculated to measure the algorithm accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.02702702702702703\n",
      "Learned classification GBT model:\n",
      "TreeEnsembleModel classifier with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 434 <= 0.0)\n",
      "     If (feature 99 <= 0.0)\n",
      "      Predict: -1.0\n",
      "     Else (feature 99 > 0.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 434 > 0.0)\n",
      "     Predict: 1.0\n",
      "  Tree 1:\n",
      "    If (feature 434 <= 0.0)\n",
      "     If (feature 352 <= 246.0)\n",
      "      If (feature 400 <= 9.0)\n",
      "       If (feature 124 <= 0.0)\n",
      "        Predict: -0.4768116880884702\n",
      "       Else (feature 124 > 0.0)\n",
      "        Predict: -0.4768116880884703\n",
      "      Else (feature 400 > 9.0)\n",
      "       Predict: -0.4768116880884703\n",
      "     Else (feature 352 > 246.0)\n",
      "      Predict: 0.4768116880884694\n",
      "    Else (feature 434 > 0.0)\n",
      "     If (feature 467 <= 28.0)\n",
      "      If (feature 518 <= 248.0)\n",
      "       Predict: 0.47681168808847024\n",
      "      Else (feature 518 > 248.0)\n",
      "       Predict: 0.47681168808847024\n",
      "     Else (feature 467 > 28.0)\n",
      "      Predict: 0.4768116880884712\n",
      "  Tree 2:\n",
      "    If (feature 434 <= 0.0)\n",
      "     If (feature 242 <= 0.0)\n",
      "      Predict: 0.4381935810427206\n",
      "     Else (feature 242 > 0.0)\n",
      "      Predict: -0.4381935810427206\n",
      "    Else (feature 434 > 0.0)\n",
      "     If (feature 178 <= 0.0)\n",
      "      If (feature 123 <= 0.0)\n",
      "       Predict: 0.4381935810427206\n",
      "      Else (feature 123 > 0.0)\n",
      "       If (feature 124 <= 252.0)\n",
      "        Predict: 0.4381935810427206\n",
      "       Else (feature 124 > 252.0)\n",
      "        Predict: 0.43819358104272055\n",
      "     Else (feature 178 > 0.0)\n",
      "      If (feature 97 <= 0.0)\n",
      "       Predict: 0.43819358104272044\n",
      "      Else (feature 97 > 0.0)\n",
      "       Predict: 0.43819358104272044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val PATH = \"file:///Users/lzz/work/SparkML/\"\n",
    "import org.apache.spark.mllib.tree.GradientBoostedTrees\n",
    "import org.apache.spark.mllib.tree.configuration.BoostingStrategy\n",
    "import org.apache.spark.mllib.tree.model.GradientBoostedTreesModel\n",
    "import org.apache.spark.mllib.util.MLUtils\n",
    "\n",
    "// Load and parse the data file.\n",
    "val data = MLUtils.loadLibSVMFile(sc, PATH + \"data/mllib/sample_libsvm_data.txt\")\n",
    "// Split the data into training and test sets (30% held out for testing)\n",
    "val splits = data.randomSplit(Array(0.7, 0.3))\n",
    "val (trainingData, testData) = (splits(0), splits(1))\n",
    "\n",
    "// Train a GradientBoostedTrees model.\n",
    "//  The defaultParams for Classification use LogLoss by default.\n",
    "val boostingStrategy = BoostingStrategy.defaultParams(\"Classification\")\n",
    "boostingStrategy.numIterations = 3 // Note: Use more iterations in practice.\n",
    "boostingStrategy.treeStrategy.numClasses = 2\n",
    "boostingStrategy.treeStrategy.maxDepth = 5\n",
    "//  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "boostingStrategy.treeStrategy.categoricalFeaturesInfo = Map[Int, Int]()\n",
    "\n",
    "val model = GradientBoostedTrees.train(trainingData, boostingStrategy)\n",
    "\n",
    "// Evaluate model on test instances and compute test error\n",
    "val labelAndPreds = testData.map { point =>\n",
    "  val prediction = model.predict(point.features)\n",
    "  (point.label, prediction)\n",
    "}\n",
    "val testErr = labelAndPreds.filter(r => r._1 != r._2).count.toDouble / testData.count()\n",
    "println(\"Test Error = \" + testErr)\n",
    "println(\"Learned classification GBT model:\\n\" + model.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "The example below demonstrates how to load a LIBSVM data file, parse it as an RDD of LabeledPoint and then perform regression using Gradient-Boosted Trees with Squared Error as the loss. The Mean Squared Error (MSE) is computed at the end to evaluate goodness of fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error = 0.13333333333333333\n",
      "Learned regression GBT model:\n",
      "TreeEnsembleModel regressor with 3 trees\n",
      "\n",
      "  Tree 0:\n",
      "    If (feature 405 <= 0.0)\n",
      "     If (feature 99 <= 0.0)\n",
      "      Predict: 0.0\n",
      "     Else (feature 99 > 0.0)\n",
      "      Predict: 1.0\n",
      "    Else (feature 405 > 0.0)\n",
      "     Predict: 1.0\n",
      "  Tree 1:\n",
      "    Predict: 0.0\n",
      "  Tree 2:\n",
      "    Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.mllib.tree.GradientBoostedTrees\n",
    "import org.apache.spark.mllib.tree.configuration.BoostingStrategy\n",
    "import org.apache.spark.mllib.tree.model.GradientBoostedTreesModel\n",
    "import org.apache.spark.mllib.util.MLUtils\n",
    "\n",
    "// Load and parse the data file.\n",
    "val data = MLUtils.loadLibSVMFile(sc, PATH+\"data/mllib/sample_libsvm_data.txt\")\n",
    "// Split the data into training and test sets (30% held out for testing)\n",
    "val splits = data.randomSplit(Array(0.7, 0.3))\n",
    "val (trainingData, testData) = (splits(0), splits(1))\n",
    "\n",
    "// Train a GradientBoostedTrees model.\n",
    "//  The defaultParams for Regression use SquaredError by default.\n",
    "val boostingStrategy = BoostingStrategy.defaultParams(\"Regression\")\n",
    "boostingStrategy.numIterations = 3 // Note: Use more iterations in practice.\n",
    "boostingStrategy.treeStrategy.maxDepth = 5\n",
    "//  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "boostingStrategy.treeStrategy.categoricalFeaturesInfo = Map[Int, Int]()\n",
    "\n",
    "val model = GradientBoostedTrees.train(trainingData, boostingStrategy)\n",
    "\n",
    "// Evaluate model on test instances and compute test error\n",
    "val labelsAndPredictions = testData.map { point =>\n",
    "  val prediction = model.predict(point.features)\n",
    "  (point.label, prediction)\n",
    "}\n",
    "val testMSE = labelsAndPredictions.map{ case(v, p) => math.pow((v - p), 2)}.mean()\n",
    "println(\"Test Mean Squared Error = \" + testMSE)\n",
    "println(\"Learned regression GBT model:\\n\" + model.toDebugString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.5.2 (Scala 2.10)",
   "language": "",
   "name": "spark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
